{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 107
        },
        "colab_type": "code",
        "id": "8V3gMQlsEKCz",
        "outputId": "f67e034f-7f3d-4e66-8fe0-1884f9815ac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m[datasets/sim] Number of 'vali' light-view combinations: 5\u001b[0m\n",
            "\u001b[36m[models/base] Layers registered as trainable:\n",
            "\t['net_coarse_enc_layer0', 'net_coarse_enc_layer1', 'net_coarse_enc_layer2', 'net_coarse_enc_layer3', 'net_coarse_enc_layer4', 'net_coarse_enc_layer5', 'net_coarse_enc_layer6', 'net_coarse_enc_layer7', 'net_coarse_a_out_layer0', 'net_coarse_bottleneck_layer0', 'net_coarse_rgb_out_layer0', 'net_coarse_rgb_out_layer1', 'net_fine_enc_layer0', 'net_fine_enc_layer1', 'net_fine_enc_layer2', 'net_fine_enc_layer3', 'net_fine_enc_layer4', 'net_fine_enc_layer5', 'net_fine_enc_layer6', 'net_fine_enc_layer7', 'net_fine_a_out_layer0', 'net_fine_bottleneck_layer0', 'net_fine_rgb_out_layer0', 'net_fine_rgb_out_layer1']\u001b[0m\n",
            "Inference done"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from google3.pyglib import gfile\n",
        "from google3.experimental.users.xiuming.sim.sim import datasets, models\n",
        "from google3.experimental.users.xiuming.sim.sim.util import io as ioutil, \\\n",
        "    logging as logutil\n",
        "\n",
        "\n",
        "def query_opacity(model, pts, voxel_size, use_fine=False, mlp_chunk=65536):\n",
        "    pref = 'fine_' if use_fine else 'coarse_'\n",
        "    enc = model.net[pref + 'enc']\n",
        "    a_out = model.net[pref + 'a_out']\n",
        "    embedder = model.embedder['xyz']\n",
        "    pts_flat = tf.reshape(pts, (-1, 3))\n",
        "    # Chunk by chunk to avoid OOM\n",
        "    a_chunks = []\n",
        "    for i in range(0, pts_flat.shape[0], mlp_chunk):\n",
        "        pts_chunk = pts_flat[i:min(pts_flat.shape[0], i + mlp_chunk)]\n",
        "        pts_embed = embedder(pts_chunk)\n",
        "        feat = enc(pts_embed)\n",
        "        a_flat = a_out(feat)\n",
        "        a_chunks.append(a_flat)\n",
        "    a_flat = tf.concat(a_chunks, axis=0)\n",
        "    opacity_flat = 1.0 - tf.exp(-tf.nn.relu(a_flat) * voxel_size)\n",
        "    opacity = tf.reshape(opacity_flat, pts.shape[:3])\n",
        "    return opacity\n",
        "\n",
        "\n",
        "def gen_para_rays(\n",
        "        n_voxels_per_unit, x_min=-0.3, x_max=0.3, y_min=0., y_max=1.8,\n",
        "        z_min=2.8, z_max=3.2):\n",
        "    \"\"\"Ensures the volume is square, and all voxels are of the same size.\n",
        "    \"\"\"\n",
        "    # go/holodeck-output-api#cameras\n",
        "    n_x = int((x_max - x_min) * n_voxels_per_unit)\n",
        "    n_y = int((y_max - y_min) * n_voxels_per_unit)\n",
        "    n_z = int((z_max - z_min) * n_voxels_per_unit)\n",
        "    x = tf.linspace(x_min, x_max, n_x) # +X is from right to left arm\n",
        "    y = tf.linspace(y_min, y_max, n_y) # +Y is from feet to head\n",
        "    z = tf.linspace(z_min, z_max, n_z) # +Z is from back to chest\n",
        "    x = tf.cast(x, tf.float32)\n",
        "    y = tf.cast(y, tf.float32)\n",
        "    z = tf.cast(z, tf.float32)\n",
        "    xyz = tf.stack(tf.meshgrid(x, y, z, indexing='xy'), axis=-1)\n",
        "    return xyz\n",
        "\n",
        "\n",
        "def get_config_ini(ckpt_path):\n",
        "    return '/'.join(ckpt_path.split('/')[:-2]) + '.ini'\n",
        "\n",
        "\n",
        "def make_datapipe(config):\n",
        "    dataset_name = config.get('DEFAULT', 'dataset')\n",
        "    Dataset = datasets.get_dataset_class(dataset_name)\n",
        "    dataset = Dataset(config, 'vali')\n",
        "\n",
        "    no_batch = config.getboolean('DEFAULT', 'no_batch')\n",
        "    datapipe = dataset.build_pipeline(no_batch=no_batch)\n",
        "    return datapipe\n",
        "\n",
        "\n",
        "def restore_model(config, ckpt_path):\n",
        "    model_name = config.get('DEFAULT', 'model')\n",
        "    Model = models.get_model_class(model_name)\n",
        "    model = Model(config)\n",
        "\n",
        "    model.register_trainable()\n",
        "\n",
        "    # Resume from checkpoint\n",
        "    assert model.trainable_registered, (\n",
        "        \"Register the trainable layers to have them restored from the \"\n",
        "        \"checkpoint\")\n",
        "    ckpt = tf.train.Checkpoint(net=model)\n",
        "    ckpt.restore(ckpt_path).expect_partial()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def main():\n",
        "    ckpt_path = '/cns/is-d/home/gcam-eng/gcam/interns/xiuming/sim/output/nerf_repro/324_20190806_134352_viewsyn_0235_transp-bg/lr:0.0001|mgm:-1/vis_test/ckpt-169'\n",
        "    n_voxels_per_unit = 128\n",
        "    \n",
        "    config_ini = get_config_ini(ckpt_path)\n",
        "    config = ioutil.read_config(config_ini)\n",
        "    \n",
        "    # Make dataset\n",
        "    datapipe = make_datapipe(config)\n",
        "    \n",
        "    # Restore model\n",
        "    model = restore_model(config, ckpt_path)\n",
        "    \n",
        "    # Generate rays starting at the XY plane, parallel to the Z axis\n",
        "    xyz = gen_para_rays(n_voxels_per_unit)\n",
        "    voxel_size = 1. / n_voxels_per_unit\n",
        "    \n",
        "    # Compute alpha (probability of being absorbed) at each location\n",
        "    mlp_chunk = config.getint('DEFAULT', 'mlp_chunk')\n",
        "    with tf.GradientTape() as tape:\n",
        "        opacity = query_opacity(model, xyz, voxel_size, use_fine=True, mlp_chunk=mlp_chunk)\n",
        "    print(\"Inference done\")\n",
        "    \n",
        "    # Plot\n",
        "    xyz = xyz.numpy()\n",
        "    opacity = opacity.numpy()\n",
        "    fig = go.Figure(\n",
        "        data=go.Volume(\n",
        "            x=xyz[:, :, :, 0].flatten(), y=xyz[:, :, :, 1].flatten(),\n",
        "            z=xyz[:, :, :, 2].flatten(), value=opacity.flatten(),\n",
        "            isomin=0., isomax=1., opacity=0.1, surface_count=16),\n",
        "        layout=go.Layout(scene=dict(aspectmode='data')))\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "normals_from_volume.ipynb",
      "provenance": [
        {
          "file_id": "1Qc25sP_yHAIAQDXfnw0nDxOzCykLxNC5",
          "timestamp": 1594158390324
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
